{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2067214-d64d-43b3-944d-1b1893b92264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, Aer, execute, transpile\n",
    "from qiskit.algorithms import FasterAmplitudeEstimation, EstimationProblem\n",
    "from qiskit.quantum_info import Statevector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9ee87-59c1-404c-8ad6-a34a6c517239",
   "metadata": {},
   "source": [
    "# Variational quantum sampling for probability distribution approximation\n",
    "- [Quantum self-learning Monte Carlo with quantum Fourier transform sampler](https://arxiv.org/abs/2005.14075)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e11bb3-165f-462c-9054-b4ef4bb3d1fa",
   "metadata": {},
   "source": [
    "**Quantum Fourier Transform**\n",
    "\n",
    "To start things off, we are going to define a function that returns a QFT circuit. We don't use Qiskit's native implementation to get more control over our circuits and facilitate further debugging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7484b19-8396-4728-b302-050f256d5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qft(n):\n",
    "    qc = QuantumCircuit(n)\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        qc.h(i)\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            x = 2 ** (j - i)\n",
    "            qc.cp(np.pi * x, i, j)\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c404e2-f400-47b9-97dd-56525a6df454",
   "metadata": {},
   "outputs": [],
   "source": [
    "qft(4).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b10662-c905-43cf-9410-9d2d3e794869",
   "metadata": {},
   "source": [
    "**One-dimensional QFT sampler**\n",
    "\n",
    "Using our QFT circuit, we can construct the sampler circuit. This is an $n$-qubit circuit consisting of two registers: $|\\text{in}\\rangle$ of size $m$ and $|0\\rangle^{n-m}$. The variational parameters will be firstly encoded into the $|\\text{in}\\rangle$ register by setting its state into the state\n",
    "\n",
    "$$ |\\text{in}\\rangle = \\sum_{i=0}^{2^m - 1} \\theta_i|i\\rangle,$$\n",
    "\n",
    "where $\\theta = [\\theta_0, \\theta_1, \\cdots, \\theta_{2^m - 1}]$ with $\\theta \\in \\mathbb{C}$ and is our parameter vector which has unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b8376-a081-4957-822e-299e5d064411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sampler(n, m, params):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        n: int\n",
    "            Number of qubits in sampler\n",
    "        m: int\n",
    "            Number of qubits in parametrized register\n",
    "        params: list[complex]\n",
    "            List of of size 2**m of complex parameters\n",
    "    \"\"\"\n",
    "    p  = QuantumRegister(m, \"in\")\n",
    "    g  = QuantumRegister(n - m, \"g\")\n",
    "    qc = QuantumCircuit(p, g)\n",
    "    \n",
    "    # Encode parameters into first m qubits\n",
    "    qc.initialize(params, p)\n",
    "    \n",
    "    # Perform QFT\n",
    "    qc.compose(qft(n), inplace=True)\n",
    "    \n",
    "    return transpile(qc, basis_gates=[\"cx\", \"u\"], optimization_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845452ec-3005-4db4-9391-f86f2abe7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "params  = np.random.random(2 ** 2) + np.random.random(2 ** 2) * 1j\n",
    "params  = params / np.linalg.norm(params)\n",
    "sampler = one_sampler(5, 2, params)\n",
    "sampler.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802b5f2-b4bd-43f4-a81c-ae64c033f357",
   "metadata": {},
   "source": [
    "**Probability of random variable from circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ae38f-15ca-4924-b0f7-bbb44fcdaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_from_circ(qc, r, backend=Aer.get_backend(\"statevector_simulator\"), shots=10000, delta=0.01, maxiter=3):\n",
    "    \"\"\"\n",
    "    Calculate |<r|psi>|**2 where r is the sample and psi the final state of the circuit\n",
    "    \n",
    "    Parameters:\n",
    "        qc: QuantumCircuit\n",
    "            Circuit that prepares final state\n",
    "        r: int\n",
    "            Random variable to sample\n",
    "        backend: AerBackend\n",
    "            Backend to run circuit on\n",
    "        shots: int\n",
    "            Number of shots per circuit\n",
    "        delta: float\n",
    "            Accuracy for FAE algorithm\n",
    "        maxiter: int\n",
    "            Iterations for FAE algorithm\n",
    "    \"\"\"\n",
    "    b    = format(r, 'b').zfill(qc.num_qubits)[::-1]\n",
    "    qc_i = qc.copy()\n",
    "    for i in range(qc.num_qubits):\n",
    "        if b[i] == \"0\":\n",
    "            qc_i.x(i)\n",
    "            \n",
    "    problem = EstimationProblem(\n",
    "        state_preparation = qc_i,\n",
    "        objective_qubits  = [i for i in range(qc.num_qubits)],\n",
    "    )\n",
    "\n",
    "    fae = FasterAmplitudeEstimation(\n",
    "        delta            = delta,\n",
    "        maxiter          = maxiter,\n",
    "        quantum_instance = backend,\n",
    "    )\n",
    "    result = fae.estimate(problem)\n",
    "    \n",
    "    return result.estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a975c7-7de3-4b63-a2ca-91748bcb09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params  = np.random.random(2 ** 2) + np.random.random(2 ** 2) * 1j\n",
    "params  = params / np.linalg.norm(params)\n",
    "sampler = one_sampler(4, 2, params)\n",
    "\n",
    "vec = Statevector(sampler).data\n",
    "for i in range(len(vec)):\n",
    "    vec[i] = np.real(vec[i] * np.conj(vec[i]))\n",
    "\n",
    "total = 0\n",
    "for var in range(2**4):\n",
    "    prob   = prob_from_circ(sampler, var)\n",
    "    total += prob\n",
    "    print(f\"Experimental p({var}) = {prob}. Theoretical: {np.round(vec[var], 4)}.\")\n",
    "    \n",
    "print(f\"Total probability: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f24431-c77e-4c84-8e10-4663d267767c",
   "metadata": {},
   "source": [
    "**Multistage QFT sampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75c8a4-fe3c-4c4d-834e-72ef4f811b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_sampler(D, n, m, params):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        D: int\n",
    "            Dimension of independent target distribution\n",
    "        n: int\n",
    "            Number of qubits in each one dimensional sampler\n",
    "        m: int\n",
    "            Number of qubits in parametrized register\n",
    "        params: list[list[complex]]\n",
    "            List of size D of lists of complex parameters of size 2 ** m\n",
    "            This need to be already processed with function\n",
    "    \"\"\"\n",
    "    circs = []\n",
    "    for k in range(D):\n",
    "        circs.append(one_sampler(n, m, params[k]))\n",
    "    return circs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a3df2-4452-4c52-8ed5-861d59656193",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2\n",
    "n = 4\n",
    "m = 2\n",
    "\n",
    "params = []\n",
    "for _ in range(D):\n",
    "    params.append(np.random.random(2 ** m) + np.random.random(2 ** m) * 1j)\n",
    "\n",
    "funcs = [\n",
    "    lambda var, theta: theta / (np.sqrt(np.dot(theta, theta.conj()))),\n",
    "    lambda var, theta: theta / (np.sqrt(np.dot(theta, theta.conj())))\n",
    "]\n",
    "\n",
    "r          = np.random.randint(2**m, size=D) # we need to define the random variable to sample\n",
    "new_params = []\n",
    "for k in range(len(params)):\n",
    "    new_params.append(funcs[k](r[0:k], params[k]))\n",
    "circs = multi_sampler(D, n, m, new_params)\n",
    "\n",
    "for i in range(D):\n",
    "    print(f\"Sampler {i}:\")\n",
    "    display(circs[i].draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed129c52-b952-4cf1-a334-21c420d6f592",
   "metadata": {},
   "source": [
    "For convenience, we can take the code that computes the processed parameters and turn it into a function that will come in handy later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511edb1d-a77e-47e2-8573-09bf1334d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_params(r, funcs, params):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        r: list[int]\n",
    "            Multi-dimensional random variable\n",
    "        funcs: list[lambda or func]\n",
    "            List of processing functions\n",
    "        params: list[list[complex]]\n",
    "            List of lists of complex parameters\n",
    "    \"\"\"\n",
    "    new_params = []\n",
    "    for k in range(len(params)):\n",
    "        new_params.append(funcs[k](r[0:k], params[k]))\n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7ef18-9149-4548-a61a-48ba15dc6e67",
   "metadata": {},
   "source": [
    "**Probability from multistage sampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5bb01-d4c1-4568-8be4-bf6b7948f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_from_multi_circ(q, r, backend=Aer.get_backend(\"statevector_simulator\"), shots=10000):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        q: list[QuantumCircuits]\n",
    "            List of circuits that approximate distribution\n",
    "        r: list[int]\n",
    "            Multi-dimensional random variable\n",
    "        backend: AerBackend\n",
    "            Backend to run circuits on\n",
    "        shots: int\n",
    "            Number of shots per circuit\n",
    "    \"\"\"\n",
    "    q_x = 1\n",
    "    for i in range(len(r)):\n",
    "        q_x *= prob_from_circ(q[i], r[i], backend=backend, shots=shots)\n",
    "    return q_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb70491-c36d-42b7-9ede-e9df949a51cc",
   "metadata": {},
   "source": [
    "**Cross entropy**\n",
    "\n",
    "Given a target probability distribution $p(x)$ which is hard to sample but easily computable for a given $x$, and a proposal probability $q(x)$ in the form of a one- or multi-stage QFT sampler, we will use the cross entropy as a measure to quantify the similarity of these two distributions. This is given by:\n",
    "\n",
    "$$ H(p, q) = - \\sum_x p(x) \\log q(x; \\theta)$$\n",
    "\n",
    "This measure will also be used as our loss function $L(\\theta)$. We are going to use the logarightm base 2 to work on units of bits, which is more intuitive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f94ce-a364-4054-a99d-8e3d8665776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(p, q, r, mode, backend=Aer.get_backend(\"statevector_simulator\"), shots=10000):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        p: lambda or func\n",
    "            Function to compute p(x)\n",
    "        q: QuantumCircuit or list[int, int, int, list[list[complex]], list[func]]\n",
    "            If one-dimensional, it should be a single circuit\n",
    "            If multisampler, it should be a list of arguments with\n",
    "            D, n, m, params and funcs\n",
    "        r: list[int] or list[list[int]]\n",
    "            If one-dimensional, it should be a list of integers\n",
    "            If multisampler, if should be a list of lists of integers,\n",
    "            each with same length as number of samplers\n",
    "        mode: str\n",
    "            \"one\" for one qubit sampler and \"multi\" for multistage\n",
    "        backend: AerBackend\n",
    "            Backend to run circuits on\n",
    "        shots: int\n",
    "            Number of shots for each sampler\n",
    "    \"\"\"\n",
    "    entropy = 0\n",
    "    \n",
    "    all_q_x = []\n",
    "    for var in r:\n",
    "        if mode == \"one\":\n",
    "            all_q_x.append(prob_from_circ(q, var, backend=backend, shots=shots))\n",
    "        else:\n",
    "            all_q_x.append(prob_from_multi_circ(multi_sampler(q[0], q[1], q[2], process_params(var, q[4], q[3])), \n",
    "                                                var, backend=backend, shots=shots))\n",
    "            \n",
    "    for i in range(len(r)):\n",
    "        if np.isclose(all_q_x[i], 0):\n",
    "            continue\n",
    "        entropy += p(r[i]) * np.log2(all_q_x[i])\n",
    "        \n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a408a2b-5aa8-4c2c-92da-08f23c2a89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "n = 4\n",
    "m = 2\n",
    "\n",
    "# For this example we experiment with a Linear Basis Regression Model\n",
    "# in the second and third samplers, the first one remains the identity\n",
    "\n",
    "params = []\n",
    "\n",
    "# Params for first sampler\n",
    "params.append(np.random.random(2 ** m) + np.random.random(2 ** m) * 1j)\n",
    "\n",
    "# Params for second and third sampler\n",
    "# Needs two (three) 2**m dimensional vectors\n",
    "params.append([np.random.random(2 ** m) + np.random.random(2 ** m) * 1j for _ in range(2)])\n",
    "params.append([np.random.random(2 ** m) + np.random.random(2 ** m) * 1j for _ in range(3)])\n",
    "\n",
    "# Define LBRM function for second and third samplers\n",
    "def lbrm(var, theta):\n",
    "    vec = np.array(theta[-1])\n",
    "    for i in range(len(var)):\n",
    "        vec += var[i] * theta[i]\n",
    "    return vec / np.sqrt(np.dot(vec, vec.conj()))\n",
    "\n",
    "funcs = [\n",
    "    lambda var, theta: theta / (np.sqrt(np.dot(theta, theta.conj()))),\n",
    "    lbrm,\n",
    "    lbrm,\n",
    "]\n",
    "\n",
    "r     = np.random.randint(2**m, size=D)\n",
    "circs = multi_sampler(D, n, m, process_params(r, funcs, params))\n",
    "\n",
    "for i in range(D):\n",
    "    print(f\"Sampler {i}:\")\n",
    "    display(circs[i].draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2c4b8-2716-479d-b0a5-5f90dce97de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make the target distribution be an equal distribution\n",
    "# There are 3 random variables, each with 2**4 possible values,\n",
    "# therefore there are 4096 total random variables\n",
    "def target(x):\n",
    "    return 1 / 4096\n",
    "\n",
    "# We will only sample 64 random variables for efficiency\n",
    "r_var = []\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for k in range(4):\n",
    "            r_var.append([i, j, k])\n",
    "\n",
    "# Note that the result is not favorable since we don't optimize anything yet\n",
    "entropy = cross_entropy(target, [D, n, m, params, funcs], r_var, mode=\"multi\")\n",
    "print(f\"Calculated cross entropy: {entropy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b8112-905e-4148-a973-84dfe7a1549a",
   "metadata": {},
   "source": [
    "**Gradient of $L(\\theta)$**\n",
    "\n",
    "Before calculating the gradient of the loss function, we need to be able to calculate the partial derivative of a one-qubit sampler with respect to $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af251b-9ffb-48b6-89f1-4fad848a8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_qft_x_j(x, j, N):\n",
    "    \"\"\"\n",
    "    Return the j element of the x row of the unitary of QFT of size N\n",
    "    \"\"\"\n",
    "    return (1 / np.sqrt(2**N)) * np.exp(1j * 2 * np.pi * x * j / (2 ** N))\n",
    "\n",
    "def qft_derivative(x, theta, N):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x: int\n",
    "            Random variable\n",
    "        theta: list[complex]\n",
    "            List of complex parameters\n",
    "        N: int\n",
    "            Number of qubits in sampler\n",
    "    \"\"\"\n",
    "    m   = len(theta)\n",
    "    u_x = np.array([u_qft_x_j(x, j, N) for j in range(m)])\n",
    "    dot = np.dot(u_x.conj(), theta.conj())\n",
    "    return dot * u_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dbaca-1ff4-4a96-8db6-8666f571233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params  = np.random.random(2 ** 2) + np.random.random(2 ** 2) * 1j\n",
    "params  = params / np.linalg.norm(params)\n",
    "qft_derivative(3, params, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b66ff-af55-42db-ac82-332e2ada7201",
   "metadata": {},
   "source": [
    "Now we can compute the total gradient. We will do this for the case of a one-qubit sampler, and then use that function to compute the case of a multistage sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3db8b-541e-47e8-839d-1bd68def3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_loss_gradient(p, q, r, params, backend=Aer.get_backend(\"statevector_simulator\"), shots=10000):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        p: lambda or func\n",
    "            Function to compute p(x)\n",
    "        q: QuantumCircuit\n",
    "            Circuit approximating target distribution\n",
    "        r: list[int]\n",
    "            List of random variables to calculate gradient with\n",
    "        params: list[complex]\n",
    "            List of complex parameters\n",
    "        backend: AerBackend\n",
    "            Backend to run circuits on\n",
    "        shots: int\n",
    "            Number of shots for each sampler\n",
    "    \"\"\"\n",
    "    B    = len(r)\n",
    "    N    = q.num_qubits\n",
    "    grad = np.zeros(len(params), dtype=\"complex\")\n",
    "    \n",
    "    for i in range(B):\n",
    "        num   = p(r[i])\n",
    "        den   = prob_from_circ(q, r[i], backend=backend, shots=shots)**2\n",
    "        if den == 0:\n",
    "            frac = num / 10e-5\n",
    "        else:\n",
    "            frac = num / den\n",
    "        grad += frac * qft_derivative(r[i], params, N)\n",
    "        \n",
    "    return - (1 / B) * grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaff944-e454-4a31-b5a0-ac438ed7bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params  = np.random.random(2 ** 2) + np.random.random(2 ** 2) * 1j\n",
    "params  = params / np.linalg.norm(params)\n",
    "sampler = one_sampler(5, 2, params)\n",
    "\n",
    "def target(x):\n",
    "    return 1 / (2 ** 5)\n",
    "\n",
    "one_loss_gradient(target, sampler, [i for i in range(2**5)], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a7ba2-216f-4d08-95c1-825ef79ee2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_gradient_change(mu, grad, prev_grad):\n",
    "    m = (mu * prev_grad) + ((1 - mu) * grad.conj())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183b2c1-51db-4a61-bc0d-17baedee8c3e",
   "metadata": {},
   "source": [
    "Finally, we can expand to the multisampler case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e463c83-e17b-49db-8faf-ff95695e85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss_gradient(p, q, r, params, funcs, backend=Aer.get_backend(\"statevector_simulator\"), shots=10000):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        p: lambda or func\n",
    "            Function to compute p(x)\n",
    "        q: list[int, int, int]\n",
    "            Arguments to create multisampler, it should\n",
    "            be a list of arguments with D, n, and m\n",
    "        r: list[list[int]]\n",
    "            List of random variables to calculate gradient with\n",
    "        params: list[list[complex]]\n",
    "            List of complex parameters\n",
    "        funcs: list[lambda or func]\n",
    "            List of functions\n",
    "        backend: AerBackend\n",
    "            Backend to run circuits on\n",
    "        shots: int\n",
    "            Number of shots for each sampler\n",
    "    \"\"\"\n",
    "    D    = q[0]\n",
    "    n    = q[1]\n",
    "    m    = q[2]\n",
    "    B    = len(r)\n",
    "    grad = []\n",
    "    \n",
    "    # TODO: derivative of function\n",
    "    for k in range(len(params)):\n",
    "        grad_k = np.zeros(2**m, dtype=\"complex\")\n",
    "        for i in range(B):\n",
    "            new_params = np.array(process_params(r[i], funcs, params))\n",
    "            circs      = multi_sampler(D, n, m, new_params)\n",
    "            frac_1     = qft_derivative(r[i][k], new_params[k], n) / prob_from_circ(circs[k], r[i][k], backend=backend, shots=shots)\n",
    "            frac_2     = p(r[i]) / prob_from_multi_circ(circs, r[i], backend=backend, shots=shots)\n",
    "            grad_k    += frac_1 * frac_2\n",
    "        grad.append(- (1 / B) * grad_k)\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc994174-1e16-4182-a90c-af9bd30354b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "n = 4\n",
    "m = 2\n",
    "\n",
    "params = []\n",
    "params.append(np.random.random(2 ** m) + np.random.random(2 ** m) * 1j)\n",
    "params.append([np.random.random(2 ** m) + np.random.random(2 ** m) * 1j for _ in range(2)])\n",
    "params.append([np.random.random(2 ** m) + np.random.random(2 ** m) * 1j for _ in range(3)])\n",
    "\n",
    "funcs = [\n",
    "    lambda var, theta: theta / (np.sqrt(np.dot(theta, theta.conj()))),\n",
    "    lbrm,\n",
    "    lbrm\n",
    "]\n",
    "\n",
    "def target(x):\n",
    "    return 1 / (4096)\n",
    "\n",
    "var = []\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            var.append([i, j, k])\n",
    "\n",
    "gradient = multi_loss_gradient(target, [D, n, m], var, params, funcs)\n",
    "for i, grad in enumerate(gradient):\n",
    "    print(f\"Gradient {i}: {grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2be835-de08-47f2-bb8b-0691d3083dca",
   "metadata": {},
   "source": [
    "**Accepting samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af61f08-005d-4daa-8524-575471615b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept(p, q, r, r_hat, backend=Aer.get_backend(\"statevector_simulator\"), shots=10000):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        p: lambda or func\n",
    "            Function to compute p(x)\n",
    "        q: QuantumCircuit or list[int, int, int, list[], list[]]\n",
    "            Circuit or arguments to create circuit that\n",
    "            approximate distribution. List should have\n",
    "            D, n, m, funcs, and params. \n",
    "        r: int or list[int]\n",
    "            Last accepted sample\n",
    "        r_hat: int or list[int]\n",
    "            Sample to accept or reject\n",
    "        backend: AerBackend\n",
    "            Backend to run circuits on\n",
    "        shots: int\n",
    "            Number of shots for each sampler\n",
    "    \"\"\"\n",
    "    if isinstance(r, int):\n",
    "        num = p(r_hat) * prob_from_circ(q, r, backend=backend, shots=shots)\n",
    "        den = p(r) * prob_from_circ(q, r_hat, backend=backend, shots=shots)\n",
    "    else:\n",
    "        D      = q[0]\n",
    "        n      = q[1]\n",
    "        m      = q[2]\n",
    "        funcs  = q[3]\n",
    "        params = q[4]\n",
    "        \n",
    "        q_r  = multi_sampler(D, n, m, process_params(r, funcs, params))\n",
    "        q_rh = multi_sampler(D, n, m, process_params(r_hat, funcs, params))\n",
    "        \n",
    "        num = p(r_hat) * prob_from_multi_circ(q_r, r, backend=backend, shots=shots)\n",
    "        den = p(r) * prob_from_multi_circ(q_rh, r_hat, backend=backend, shots=shots)\n",
    "    if den != 0:\n",
    "        prob = num / den\n",
    "    else:\n",
    "        prob = float(\"inf\")\n",
    "    return np.random.rand() < min([1, prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b44dc-f918-481c-a240-e658d3ae1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2\n",
    "n = 4\n",
    "m = 2\n",
    "\n",
    "params = []\n",
    "for _ in range(D):\n",
    "    params.append(np.random.random(2 ** m) + np.random.random(2 ** m) * 1j)\n",
    "\n",
    "funcs = [\n",
    "    lambda var, theta: theta / (np.sqrt(np.dot(theta, theta.conj()))),\n",
    "    lambda var, theta: theta / (np.sqrt(np.dot(theta, theta.conj())))\n",
    "]\n",
    "\n",
    "def target(x):\n",
    "    return 1 / 256\n",
    "\n",
    "r        = np.random.randint(2**n, size=D) # set some starting variable\n",
    "accepted = [r]\n",
    "counter  = 0\n",
    "for i in range(10): # test 10 random variables\n",
    "    while True:\n",
    "        r_hat = np.random.randint(2**n, size=D)\n",
    "        counter += 1\n",
    "        if accept(target, [D, n, m, funcs, params], r, r_hat):\n",
    "            accepted.append(r_hat)\n",
    "            r = r_hat\n",
    "            break\n",
    "print(f\"Total tested: {counter}. Accepted: {len(accepted)-1}.\")\n",
    "print(accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df553ddb-8687-4e88-8424-c68030d5c114",
   "metadata": {},
   "source": [
    "**Approximating one-dimensional distributions**\n",
    "\n",
    "Now that we have everything we need in place, we can start testing out our algorithm. First, we will work with the one-dimensional sampler to approximate probability distributions that depend on one-dimensional random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef24705-8f54-4fed-aab0-af7ae0109432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65505bfe-3825-424a-9df6-6c119e854509",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (9,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601bdec-cc07-4ca1-986b-e6b79ddd73ef",
   "metadata": {},
   "source": [
    "We are going to start trying to approximate a simple normal distribution. We are going to use 5 qubits, so the random variable will be in the range $[0, 32)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4933d1bc-2831-4f50-9a1c-1c1bebb7e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "std  = (2**5-1) / 6\n",
    "mean = (2**5-1) / 2\n",
    "norm = stats.norm(loc=mean, scale=std)\n",
    "x    = np.linspace(norm.ppf(0.01), norm.ppf(0.99), 100)\n",
    "plt.plot(x, norm.pdf(x), 'b-', lw=5, alpha=0.6, label='normal pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc12590-25bd-40d7-b840-f3c8ccceaa7a",
   "metadata": {},
   "source": [
    "We are going to use $2$ qubits to encode the complex parameters. This time, we will be smarter when choosing our starting parameters. We will choose the parameters such that they give an equal superposition of all states in the final state. As you can see in the cell below, this is done by setting the initial parameters to $\\left[\\sqrt{\\frac{1}{2^{m-1}}} + \\sqrt{\\frac{1}{2^{m-1}}}i, 0, \\cdots, 0\\right]$. Then, we will optimize these parameters to accurately approximate the normal distribution. So, we initialize the sampler will look as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e8ba5-7d35-408b-841d-4b5f2f10f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "m = 2\n",
    "\n",
    "params    = np.zeros(2**m, dtype=\"complex\")\n",
    "params[0] = np.sqrt(1 / (2 ** (m - 1))) + np.sqrt(1 / (2 ** (m - 1))) * 1j\n",
    "sampler   = one_sampler(n, m, params)\n",
    "\n",
    "Statevector(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a5b2a-9ce3-4efd-8923-abf246bcb004",
   "metadata": {},
   "source": [
    "Here we have some parameters that give an equal superposition after going through the QFT. In other words, we have a sampler that represents a uniform distribution in the range $[0, 32)$. Therefore, it is worth exploring the cross entropy, acceptance ratio and change in the parameters after one learning step of this sampler to make sure all the functions we have defined up to this point are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ee0f1-7ca5-49c6-8ba3-6bdaae219ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "def uniform(x):\n",
    "    return 1 / 32\n",
    "\n",
    "s  = Statevector(sampler).data\n",
    "x  = np.array([i for i in range(2**n)])\n",
    "y1 = [np.real(np.dot(s[i], s[i].conj())) for i in x]\n",
    "y2 = [uniform(x) for i in x]\n",
    "\n",
    "ax.set_ylim([0, 0.06])\n",
    "ax.plot(x, y1, 'r-', lw=5, alpha=0.6, label='sampler pdf')\n",
    "ax.plot(x, y2, 'b-', lw=5, alpha=0.6, label='uniform pdf')\n",
    "ax.legend()\n",
    "\n",
    "r       = 0\n",
    "samples = [r]\n",
    "for r_hat in range(1, 32):\n",
    "    if accept(uniform, sampler, r, r_hat):\n",
    "        samples.append(r_hat)\n",
    "        r = r_hat\n",
    "\n",
    "entropy = cross_entropy(uniform, sampler, [i for i in range(2**n)], mode=\"one\")\n",
    "\n",
    "grad       = one_loss_gradient(uniform, sampler, [i for i in range(2**n)], params)\n",
    "alpha      = 0.01\n",
    "mu         = 0.9\n",
    "new_params = params - alpha * one_gradient_change(mu, grad, 0)\n",
    "new_params = new_params / np.linalg.norm(new_params)\n",
    "\n",
    "print(f\"Cross entropy of sampler against target: {entropy}.\")\n",
    "print(f\"Acceptance ratio of {len(samples) / 32}.\")\n",
    "print(f\"Euclidean norm between initial and udpated params: {np.linalg.norm(params - new_params)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9568bf4-c3b5-4fe1-987b-66a4260bd103",
   "metadata": {},
   "source": [
    "As you can see, we have that the cross entropy is equal to $5$ bits, which is exactly what we should expect with an uniform distribution over $2^{5}$ random variables. (Remember that the cross entropy of two distributions when they are equivalent is equal to that equivalent distribution). Then, all of the possible 32 random variables are accepted, and the difference between the initial parameters and the updated parameters after one learning step is negligible. If that is not enough, the graph also shows us that the target distribution and the distribution given by our QFT sampler are the same. Therefore, we can assure our functions are working correctly!\n",
    "\n",
    "Getting back on track with the normal distribution we will try to optimize for, to calculate the gradient of the loss function, we are going to be using $32$ samples, i.e., the whole domain in the function. We do this in this case since we have a relatively small domain, so we can take advantage of this and be more precise on our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa62ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [i for i in range(2**n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af319b-4ab8-46e0-8ed4-531e13b1a11c",
   "metadata": {},
   "source": [
    "Then we use the samples to calculate the gradient vector of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995109e-5bff-4e6d-a4ab-a8aceb8f7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = one_loss_gradient(norm.pdf, sampler, samples, params)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c9f47c-1aad-41ce-9ac9-7b9df92c3497",
   "metadata": {},
   "source": [
    "And finally we update our complex parameter vector as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783acb0-7bbf-4391-8c3d-8d431017e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha      = 0.01\n",
    "mu         = 0.9\n",
    "new_params = params - alpha * one_gradient_change(mu, grad, 0) # prev_grad is 0 here since its the first change we do\n",
    "new_params = new_params / np.linalg.norm(new_params)\n",
    "print(f\"New params: {new_params}\")\n",
    "print(f\"Difference from old params: {np.linalg.norm(new_params - params)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181a84f-d181-4f0f-b4be-f12b21d33c0a",
   "metadata": {},
   "source": [
    "This is only one step of the optimization procedure. We need to put everything we did into a loop and repeat it a large amount of times until convergence. Every 100 steps we are going to save the parameters into a CSV file so we can analyze the learning procedure of our algorithm once we reach convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e74867-97fa-494b-b7e7-a50017cd96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0d573-db7b-42dc-99d8-d2adde169af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "m = 3\n",
    "\n",
    "alpha  = 0.01\n",
    "mu     = 0.9\n",
    "change = 0\n",
    "\n",
    "std  = (2**n-1) / 6\n",
    "mean = (2**n-1) / 2\n",
    "norm = stats.norm(loc=mean, scale=std)\n",
    "\n",
    "params    = np.zeros(2**m, dtype=\"complex\")\n",
    "params[0] = 1 + 1 * 1j\n",
    "params    = params / np.linalg.norm(params)\n",
    "\n",
    "samples = [i for i in range(2**n)]\n",
    "\n",
    "d_steps  = []\n",
    "d_params = []\n",
    "\n",
    "for step in range(0, 10000):\n",
    "    # Create circuit\n",
    "    sampler = one_sampler(n, m, params)\n",
    "    \n",
    "    # Record progress every one hundred learning steps\n",
    "    if step % 100 == 0:\n",
    "        d_steps.append(step+1)\n",
    "        d_params.append(params)\n",
    "        \n",
    "        with open('data/ten_qubit_normal.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"step\", \"params\"])\n",
    "            for i in range(len(d_steps)):\n",
    "                writer.writerow([d_steps[i], d_params[i]])\n",
    "    \n",
    "    # Compute gradient\n",
    "    grad = one_loss_gradient(norm.pdf, sampler, samples, params)\n",
    "    \n",
    "    # Update parameters\n",
    "    change     = one_gradient_change(mu, grad, change)\n",
    "    new_params = params - alpha * change\n",
    "    new_params = new_params / np.linalg.norm(new_params)\n",
    "    \n",
    "    # Check for convergence\n",
    "    diff = np.linalg.norm(new_params - params)\n",
    "    if diff < 1e-18:\n",
    "        break\n",
    "\n",
    "    # If didn't converge, update parameters and continue loop\n",
    "    params = new_params\n",
    "    \n",
    "    # Print output\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Learning step: {step+1}.\")\n",
    "    print(f\"Norm change between old and updated parameters: {diff}.\")\n",
    "        \n",
    "        \n",
    "print(f\"Converged in step {step+1}.\")\n",
    "\n",
    "# Record last step and write final file\n",
    "d_steps.append(step+1)\n",
    "d_params.append(params)\n",
    "\n",
    "with open('data/ten_qubit_normal.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"step\", \"params\"])\n",
    "    for i in range(len(d_steps)):\n",
    "        writer.writerow([d_steps[i], d_params[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5218b32-c372-488a-8ddf-3750aa6d450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = one_sampler(n, m, params)\n",
    "entropy = cross_entropy(norm.pdf, sampler, [i for i in range(2**n)], mode=\"one\")\n",
    "print(f\"Cross entropy of final approximation: {entropy}\")\n",
    "\n",
    "n_entropy = (np.log2(2 * np.pi * (std**2)))/2 + 0.5\n",
    "print(f\"Entropy of normal distribution: {n_entropy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895eb162-8ccc-4f73-969f-2c4bd672b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "s = Statevector(sampler).data\n",
    "x = np.array([i for i in range(2**n)])\n",
    "y = [np.real(np.dot(s[i], s[i].conj())) for i in x]\n",
    "\n",
    "ax.plot(x, y, 'r-', lw=5, alpha=0.6, label='sampler pdf')\n",
    "ax.plot(x, norm.pdf(x), 'b-', lw=5, alpha=0.6, label='norm pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qiskit v0.34.2 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
